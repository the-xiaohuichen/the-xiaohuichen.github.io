<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title></title>
    <meta name="author" content="Xiaohui  Chen" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/usc-favicon.webp"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/people/">people</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           
          </h1>
          <p class="desc"></p>
        </header>

        <article>
          <div class="profile float-left">

              <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic.jpg-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic.jpg-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic.jpg-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

          </div>

          <div class="clearfix">
            <div>
<h1><b>Xiaohui Chen</b></h1>

<b>Associate Professor</b><br>
<a href="https://dornsife.usc.edu/mathematics/" target="_blank" rel="noopener noreferrer">Department of Mathematics</a><br>
<a href="https://www.usc.edu/" target="_blank" rel="noopener noreferrer">University of Southern California</a><br><br>


<b>Program Director</b><br>
<a href="https://dornsife.usc.edu/math-data-science/" target="_blank" rel="noopener noreferrer">Master's Program in Mathematical Data Science</a><br>
<a href="https://www.usc.edu/" target="_blank" rel="noopener noreferrer">University of Southern California</a><br><br>

<b>Office</b>: Kaprielian Hall (KAP) 406B<br>
<b>Address</b>: 3620 S. Vermont Ave., Los Angeles, CA 90089 USA<br>
<b>Lab website</b>: <a href="https://dornsife.usc.edu/mirl/" target="_blank" rel="noopener noreferrer"> Machine Intelligence Research Lab (MIRL)</a><br><br><br>


I am broadly interested in the mathematics of data science and artificial intelligence. My research work has been centered around high-dimensional statistics, machine learning and optimal transport.

</div>

          <!-- Social -->
          <div class="social">
            <div class="contact-icons">
            <a href="mailto:%78%69%61%6F%68%75%69%63@%75%73%63.%65%64%75" title="email"><i class="fas fa-envelope"></i></a>
            <a href="https://scholar.google.com/citations?user=ZKij_0cAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
            <a href="https://github.com/the-xiaohuichen" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/xiaohui-chen-b67677a0" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>
            <a href="https://twitter.com/XiaohuiChen18" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a>
            

            </div>

            <div class="contact-note">
              
            </div>
            
          </div>
          
          </div>

          
          <!-- Selected papers -->
          <div class="publications">
            <h2>selected publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="YaoChenYang2023_WPCG" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Wasserstein proximal coordinate gradient algorithms</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/rentianyao/" target="_blank" rel="noopener noreferrer">Rentian Yao</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of Machine Learning Research</em> May 2024
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2405.04628" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Motivated by approximation Bayesian computation using mean-field variational approximation and the computation of equilibrium in multi-species systems with cross-interaction, this paper investigates the composite geodesically convex optimization problem over multiple distributions. The objective functional under consideration is composed of a convex potential energy on a product of Wasserstein spaces and a sum of convex self-interaction and internal energies associated with each distribution. To efficiently solve this problem, we introduce the Wasserstein Proximal Coordinate Gradient (WPCG) algorithms with parallel, sequential and random update schemes. Under a quadratic growth (QC) condition that is weaker than the usual strong convexity requirement on the objective functional, we show that WPCG converges exponentially fast to the unique global optimum. In the absence of the QG condition, WPCG is still demonstrated to converge to the global optimal solution, albeit at a slower polynomial rate. Numerical results for both motivating examples are consistent with our theoretical findings.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">YaoChenYang2023_WPCG</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Rentian and Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2023-10-09 22:22:12 -0700}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2024-10-15 07:29:34 -0700}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{269}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-66}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wasserstein proximal coordinate gradient algorithms}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Oral</a></abbr>
</div>

  
        <!-- Entry bib key -->
        <div id="ZhuangChenYangZhang2023_NMF-BM" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/yubo-zhuang/" target="_blank" rel="noopener noreferrer">Yubo Zhuang</a>, <em>Xiaohui Chen</em>, <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>, and <a href="http://ryz.ece.illinois.edu/" target="_blank" rel="noopener noreferrer">Richard Y. Zhang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations (ICLR)</em> May 2024
          </div>
<span class="honor">
            Oral Presentation [One of 85/7262 submissions. Top 1.2%]
          </span><!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2305.18436" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Yubo02/Statistically-Optimal-K-means-Clustering-via-Nonnegative-Low-rank-Semidefinite-Programming" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>K-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the K-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed K-means formulation using a nonconvex Burer–Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves substantially smaller mis-clustering errors compared to the existing state-of-the-art.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ZhuangChenYangZhang2023_NMF-BM</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhuang, Yubo and Chen, Xiaohui and Yang, Yun and Zhang, Richard Y.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations (ICLR)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2023-06-04 11:47:33 -0700}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2024-01-16 21:35:09 -0800}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="9366690" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Cutoff for Exact Recovery of Gaussian Mixture Models</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Information Theory</em> Jun 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2001.01194" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We determine the information-theoretic cutoff value on separation of cluster centers for exact recovery of cluster labels in a K-component Gaussian mixture model with equal cluster sizes. Moreover, we show that a semidefinite programming (SDP) relaxation of the K-means clustering method achieves such sharp threshold for exact recovery without assuming the symmetry of cluster centers.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9366690</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:07:29 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:53:58 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TIT.2021.3063155}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1557-9654}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Information Theory}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4223-4238}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cutoff for Exact Recovery of Gaussian Mixture Models}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{67}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TIT.2021.3063155}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="CHEN2021303" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Diffusion K-means clustering on manifolds: Provable exact recovery via semidefinite relaxations</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Applied and Computational Harmonic Analysis</em> May 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1903.04416" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/xiaohuichen88/Diffusion-Kmeans" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce the diffusion K-means clustering method on Riemannian submanifolds, which maximizes the within-cluster connectedness based on the diffusion distance. The diffusion K-means constructs a random walk on the similarity graph with vertices as data points randomly sampled on the manifolds and edges as similarities given by a kernel that captures the local geometry of manifolds. The diffusion K-means is a multi-scale clustering tool that is suitable for data with non-linear and non-Euclidean geometric features in mixed dimensions. Given the number of clusters, we propose a polynomial-time convex relaxation algorithm via the semidefinite programming (SDP) to solve the diffusion K-means. In addition, we also propose a nuclear norm regularized SDP that is adaptive to the number of clusters. In both cases, we show that exact recovery of the SDPs for diffusion K-means can be achieved under suitable between-cluster separability and within-cluster connectedness of the submanifolds, which together quantify the hardness of the manifold clustering problem. We further propose the localized diffusion K-means by using the local adaptive bandwidth estimated from the nearest neighbors. We show that exact recovery of the localized diffusion K-means is fully adaptive to the local probability density and geometric structures of the underlying submanifolds.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CHEN2021303</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:54:12 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.acha.2020.03.002}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1063-5203}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Applied and Computational Harmonic Analysis}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Manifold clustering, K-means, Riemannian submanifolds, Diffusion distance, Semidefinite programming, Random walk on random graphs, Laplace-Beltrami operator, Mixing times, Adaptivity}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{303-347}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusion K-means clustering on manifolds: Provable exact recovery via semidefinite relaxations}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S106352032030021X}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{52}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S106352032030021X}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.acha.2020.03.002}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="https://doi.org/10.1111/rssb.12406" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Finite sample change point inference and identification for high-dimensional mean vectors</div>
          <!-- Author -->
          <div class="author">
          

          Mengjia Yu, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> Apr 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1711.08747" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Abstract Cumulative sum (CUSUM) statistics are widely used in the change point inference and identification. For the problem of testing for existence of a change point in an independent sample generated from the mean-shift model, we introduce a Gaussian multiplier bootstrap to calibrate critical values of the CUSUM test statistics in high dimensions. The proposed bootstrap CUSUM test is fully data dependent and it has strong theoretical guarantees under arbitrary dependence structures and mild moment conditions. Specifically, we show that with a boundary removal parameter the bootstrap CUSUM test enjoys the uniform validity in size under the null and it achieves the minimax separation rate under the sparse alternatives when the dimension p can be larger than the sample size n. Once a change point is detected, we estimate the change point location by maximising the ℓ∞-norm of the generalised CUSUM statistics at two different weighting scales corresponding to covariance stationary and non-stationary CUSUM statistics. For both estimators, we derive their rates of convergence and show that dimension impacts the rates only through logarithmic factors, which implies that consistency of the CUSUM estimators is possible when p is much larger than n. In the presence of multiple change points, we propose a principled bootstrap-assisted binary segmentation (BABS) algorithm to dynamically adjust the change point detection rule and recursively estimate their locations. We derive its rate of convergence under suitable signal separation and strength conditions. The results derived in this paper are non-asymptotic and we provide extensive simulation studies to assess the finite sample performance. The empirical evidence shows an encouraging agreement with our theoretical results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">https://doi.org/10.1111/rssb.12406</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Mengjia and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:16:32 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:54:35 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/rssb.12406}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{binary segmentation, bootstrap, CUSUM, change point analysis, Gaussian approximation, high-dimensional data}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{247-270}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Finite sample change point inference and identification for high-dimensional mean vectors}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12406}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{83}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12406}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/rssb.12406}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ChenKato2020_PTRF" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Jackknife multiplier bootstrap: finite sample approximations to the U-process supremum with applications</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/kkatostat/home/" target="_blank" rel="noopener noreferrer">Kengo Kato</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Probability Theory and Related Fields</em> Jul 2020
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1708.02705" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper is concerned with finite sample approximations to the supremum of a non-degenerate U-process of a general order indexed by a function class. We are primarily interested in situations where the function class as well as the underlying distribution change with the sample size, and the U-process itself is not weakly convergent as a process. Such situations arise in a variety of modern statistical problems. We first consider Gaussian approximations, namely, approximate the U-process supremum by the supremum of a Gaussian process, and derive coupling and Kolmogorov distance bounds. Such Gaussian approximations are, however, not often directly applicable in statistical problems since the covariance function of the approximating Gaussian process is unknown. This motivates us to study bootstrap-type approximations to the U-process supremum. We propose a novel jackknife multiplier bootstrap (JMB) tailored to the U-process, and derive coupling and Kolmogorov distance bounds for the proposed JMB method. All these results are non-asymptotic, and established under fairly general conditions on function classes and underlying distributions. Key technical tools in the proofs are new local maximal inequalities for U-processes, which may be useful in other problems. We also discuss applications of the general approximation results to testing for qualitative features of nonparametric functions based on generalized local U-processes.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ChenKato2020_PTRF</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Kato, Kengo}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:55:34 -0500}</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{31}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s00440-019-00936-y}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1432-2064}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Probability Theory and Related Fields}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1097--1163}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Jackknife multiplier bootstrap: finite sample approximations to the U-process supremum with applications}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s00440-019-00936-y}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{176}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s00440-019-00936-y}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/18-AOS1773" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Randomized incomplete U-statistics in high dimensions</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/kkatostat/home/" target="_blank" rel="noopener noreferrer">Kengo Kato</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The Annals of Statistics</em> Jul 2019
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1712.00771" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper studies inference for the mean vector of a high-dimensional U-statistic. In the era of big data, the dimension d of the U-statistic and the sample size n of the observations tend to be both large, and the computation of the U-statistic is prohibitively demanding. Data-dependent inferential procedures such as the empirical bootstrap for U-statistics is even more computationally expensive. To overcome such a computational bottleneck, incomplete U-statistics obtained by sampling fewer terms of the U-statistic are attractive alternatives. In this paper, we introduce randomized incomplete U-statistics with sparse weights whose computational cost can be made independent of the order of the U-statistic. We derive nonasymptotic Gaussian approximation error bounds for the randomized incomplete U-statistics in high dimensions, namely in cases where the dimension d is possibly much larger than the sample size n, for both nondegenerate and degenerate kernels. In addition, we propose generic bootstrap methods for the incomplete U-statistics that are computationally much less demanding than existing bootstrap methods, and establish finite sample validity of the proposed bootstrap methods. Our methods are illustrated on the application to nonparametric testing for the pairwise independence of a high-dimensional random vector under weaker assumptions than those appearing in the literature.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/18-AOS1773</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Kato, Kengo}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:34:05 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:57:52 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/18-AOS1773}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Annals of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Bernoulli sampling, bootstrap, Divide and conquer, Gaussian approximation, incomplete $U$-statistics, randomized inference, sampling with replacement}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3127 -- 3156}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Randomized incomplete $U$-statistics in high dimensions}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/18-AOS1773}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{47}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/18-AOS1773}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/17-AOS1563" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Gaussian and bootstrap approximations for high-dimensional U-statistics and their applications</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The Annals of Statistics</em> Jul 2018
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1610.00032" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper studies the Gaussian and bootstrap approximations for the probabilities of a nondegenerate U-statistic belonging to the hyperrectangles in \mathbbR^d when the dimension d is large. A two-step Gaussian approximation procedure that does not impose structural assumptions on the data distribution is proposed. Subject to mild moment conditions on the kernel, we establish the explicit rate of convergence uniformly in the class of all hyperrectangles in \mathbbR^d that decays polynomially in sample size for a high-dimensional scaling limit, where the dimension can be much larger than the sample size. We also provide computable approximation methods for the quantiles of the maxima of centered U-statistics. Specifically, we provide a unified perspective for the empirical bootstrap, the randomly reweighted bootstrap and the Gaussian multiplier bootstrap with the jackknife estimator of covariance matrix as randomly reweighted quadratic forms and we establish their validity. We show that all three methods are inferentially first-order equivalent for high-dimensional U-statistics in the sense that they achieve the same uniform rate of convergence over all d-dimensional hyperrectangles. In particular, they are asymptotically valid when the dimension d can be as large as O(e^n^c) for some constant c∈(0,1/7). The bootstrap methods are applied to statistical applications for high-dimensional non-Gaussian data including: (i) principled and data-dependent tuning parameter selection for regularized estimation of the covariance matrix and its related functionals; (ii) simultaneous inference for the covariance and rank correlation matrices. In particular, for the thresholded covariance matrix estimator with the bootstrap selected tuning parameter, we show that for a class of sub-Gaussian data, error bounds of the bootstrapped thresholded covariance matrix estimator can be much tighter than those of the minimax estimator with a universal threshold. In addition, we also show that the Gaussian-like convergence rates can be achieved for heavy-tailed data, which are less conservative than those obtained by the Bonferroni technique that ignores the dependency in the underlying data distribution.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/17-AOS1563</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:35:00 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:54:48 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/17-AOS1563}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Annals of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{bootstrap, Gaussian approximation, high-dimensional inference, U-statistics}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{642 -- 678}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Gaussian and bootstrap approximations for high-dimensional U-statistics and their applications}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/17-AOS1563}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{46}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/17-AOS1563}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>

          
                  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Xiaohui  Chen. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
