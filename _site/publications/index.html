<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | </title>
    <meta name="author" content="Xiaohui  Chen" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/usc-favicon.webp"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/publications/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"></a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/people/">people</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2025</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">arXiv</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="LiChen2025_EMOT" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sample complexity and weak limits of nonsmooth multimarginal Schrödinger system with application to optimal transport barycenter</div>
          <!-- Author -->
          <div class="author">
          

          Pengtao Li, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            Dec 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2502.02726" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Multimarginal optimal transport (MOT) has emerged as a useful framework for many applied problems. However, compared to the well-studied classical two-marginal optimal transport theory, analysis of MOT is far more challenging and remains much less developed. In this paper, we study the statistical estimation and inference problems for the entropic MOT (EMOT), whose optimal solution is characterized by the multimarginal Schrödinger system. Assuming only boundedness of the cost function, we derive sharp sample complexity for estimating several key quantities pertaining to EMOT (cost functional and Schrödinger coupling) from point clouds that are randomly sampled from the input marginal distributions. Moreover, with substantially weaker smoothness assumption on the cost function than the existing literature, we derive distributional limits and bootstrap validity of various key EMOT objects. As an application, we propose the multimarginal Schrödinger barycenter as a new and natural way to regularize the exact Wasserstein barycenter and demonstrate its statistical optimality.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">LiChen2025_EMOT</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Pengtao and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Sample complexity and weak limits of nonsmooth multimarginal Schr\"{o}dinger system with application to optimal transport barycenter}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="girshfeld2025neurallocalwassersteinregression" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Neural Local Wasserstein Regression</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/usc.edu/inga-girshfeld/" target="_blank" rel="noopener noreferrer">Inga Girshfeld</a>, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Conference on Topology, Algebra, and Geometry in Data Science (TAG-DS)</em> Dec 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2511.10824" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We study the estimation problem of distribution-on-distribution regression, where both predictors and responses are probability measures. Existing approaches typically rely on a global optimal transport map or tangent-space linearization, which can be restrictive in approximation capacity and distort geometry in multivariate underlying domains. In this paper, we propose the \emphNeural Local Wasserstein Regression, a flexible nonparametric framework that models regression through locally defined transport maps in Wasserstein space. Our method builds on the analogy with classical kernel regression: kernel weights based on the 2-Wasserstein distance localize estimators around reference measures, while neural networks parameterize transport operators that adapt flexibly to complex data geometries. This localized perspective broadens the class of admissible transformations and avoids the limitations of global map assumptions and linearization structures. We develop a practical training procedure using DeepSets-style architectures and Sinkhorn-approximated losses, combined with a greedy reference selection strategy for scalability. Through synthetic experiments on Gaussian and mixture models, as well as distributional prediction tasks on MNIST, we demonstrate that our approach effectively captures nonlinear and high-dimensional distributional relationships that elude existing methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">girshfeld2025neurallocalwassersteinregression</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Girshfeld, Inga and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Local Wasserstein Regression}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Topology, Algebra, and Geometry in Data Science (TAG-DS)}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">arXiv</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="xu2025scalablesecondorderriemannianoptimization" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Scalable Second-order Riemannian Optimization for K-means Clustering</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://francis-hsu.github.io/" target="_blank" rel="noopener noreferrer">Peng Xu</a>, Chun-Ying Hou, <em>Xiaohui Chen</em>, and <a href="http://ryz.ece.illinois.edu/" target="_blank" rel="noopener noreferrer">Richard Y. Zhang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            Sep 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2509.21675" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Clustering is a hard discrete optimization problem. Nonconvex approaches such as low-rank semidefinite programming (SDP) have recently demonstrated promising statistical and local algorithmic guarantees for cluster recovery. Due to the combinatorial structure of the K-means clustering problem, current relaxation algorithms struggle to balance their constraint feasibility and objective optimality, presenting tremendous challenges in computing the second-order critical points with rigorous guarantees. In this paper, we provide a new formulation of the K-means problem as a smooth unconstrained optimization over a submanifold and characterize its Riemannian structures to allow it to be solved using a second-order cubic-regularized Riemannian Newton algorithm. By factorizing the K-means manifold into a product manifold, we show how each Newton subproblem can be solved in linear time. Our numerical experiments show that the proposed method converges significantly faster than the state-of-the-art first-order nonnegative low-rank factorization method, while achieving similarly optimal statistical accuracy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">xu2025scalablesecondorderriemannianoptimization</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Peng and Hou, Chun-Ying and Chen, Xiaohui and Zhang, Richard Y.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Scalable Second-order Riemannian Optimization for $K$-means Clustering}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="zhang2024holographicdeepthermalization" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Holographic deep thermalization for secure and efficient quantum random state generation</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/bingzhi-zhang/" target="_blank" rel="noopener noreferrer">Bingzhi Zhang</a>, <a href="https://francis-hsu.github.io/" target="_blank" rel="noopener noreferrer">Peng Xu</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.usc.edu/zhuang/" target="_blank" rel="noopener noreferrer">Quntao Zhuang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Nature Communications</em> Sep 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://www.nature.com/articles/s41467-025-61546-y" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/bzGit06/HaarQML" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Quantum randomness, especially random pure states, underpins fundamental questions like black hole physics and quantum complexity, as well as in practical applications such as quantum device benchmarking and quantum advantage certification. The conventional approach for generating genuine random states, known as ‘deep thermalization’, faces significant challenges, including scalability issues due to the need for a large ancilla system and susceptibility to attacks, as demonstrated in this work. We introduce holographic deep thermalization, a secure and hardware-efficient quantum random state generator. Via a sequence of scrambling-measure-reset processes, it continuously trades space with time, and substantially reduces the required ancilla size to as small as a system-size-independent constant; at the same time, it guarantees security by eliminating quantum correlation between the data system and potential attackers. Thanks to the resource reduction, our circuit-based implementation on IBM Quantum devices achieves genuine 5-qubit random state generation utilizing only a total of 8 qubits.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2024holographicdeepthermalization</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Bingzhi and Xu, Peng and Chen, Xiaohui and Zhuang, Quntao}</span><span class="p">,</span>
  <span class="na">date</span> <span class="p">=</span> <span class="s">{2025/07/09}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2025-07-09 22:04:02 -0700}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2025-07-09 22:04:02 -0700}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41467-025-61546-y}</span><span class="p">,</span>
  <span class="na">id</span> <span class="p">=</span> <span class="s">{Zhang2025}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{2041-1723}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Communications}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6341}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Holographic deep thermalization for secure and efficient quantum random state generation}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41467-025-61546-y}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41467-025-61546-y}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">arXiv</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="kim2025sobolevgradientascentoptimal" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sobolev Gradient Ascent for Optimal Transport: Barycenter Optimization and Convergence Analysis</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/kaheon-kim/about?authuser=0/" target="_blank" rel="noopener noreferrer">Kaheon Kim</a>, <a href="https://scholar.google.com/citations?user=Fc4gd7oAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Bohan Zhou</a>, <a href="https://sites.google.com/view/changbozhu/home/" target="_blank" rel="noopener noreferrer">Changbo Zhu</a>, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            May 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2505.13660" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper introduces a new constraint-free concave dual formulation for the Wasserstein barycenter. Tailoring the vanilla dual gradient ascent algorithm to the Sobolev geometry, we derive a scalable Sobolev gradient ascent (SGA) algorithm to compute the barycenter for input distributions supported on a regular grid. Despite the algorithmic simplicity, we provide a global convergence analysis that achieves the same rate as the classical subgradient descent methods for minimizing nonsmooth convex functions in the Euclidean space. A central feature of our SGA algorithm is that the computationally expensive c-concavity projection operator enforced on the Kantorovich dual potentials is unnecessary to guarantee convergence, leading to significant algorithmic and theoretical simplifications over all existing primal and dual methods for computing the exact barycenter. Our numerical experiments demonstrate the superior empirical performance of SGA over the existing optimal transport barycenter solvers.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">kim2025sobolevgradientascentoptimal</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kim, Kaheon and Zhou, Bohan and Zhu, Changbo and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Sobolev Gradient Ascent for Optimal Transport: Barycenter Optimization and Convergence Analysis}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="KimYaoZhuChen2025_barycenter-nonconvex-concave" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Optimal transport barycenter via nonconvex concave minimax optimization</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/kaheon-kim/about?authuser=0/" target="_blank" rel="noopener noreferrer">Kaheon Kim</a>, <a href="https://sites.google.com/view/rentianyao/" target="_blank" rel="noopener noreferrer">Rentian Yao</a>, <a href="https://sites.google.com/view/changbozhu/home/" target="_blank" rel="noopener noreferrer">Changbo Zhu</a>, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Machine Learning (ICML)</em> Jul 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2501.14635" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://kaheonkim.github.io/WDHA/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The optimal transport barycenter (a.k.a. Wasserstein barycenter) is a fundamental notion of averaging that extends from the Euclidean space to the Wasserstein space of probability distributions. Computation of the \emphunregularized barycenter for discretized probability distributions on point clouds is a challenging task when the domain dimension d &gt; 1. Most practical algorithms for approximating the barycenter problem are based on entropic regularization. In this paper, we introduce a nearly linear time O(m \logm) and linear space complexity O(m) primal-dual algorithm, the \emphWasserstein-Descent \dot\mathbbH^1-Ascent (WDHA) algorithm, for computing the \emphexact barycenter when the input probability density functions are discretized on an m-point grid. The key success of the WDHA algorithm hinges on alternating between two different yet closely related Wasserstein and Sobolev optimization geometries for the primal barycenter and dual Kantorovich potential subproblems. Under reasonable assumptions, we establish the convergence rate and iteration complexity of WDHA to its stationary point when the step size is appropriately chosen. Superior computational efficacy, scalability, and accuracy over the existing Sinkhorn-type algorithms are demonstrated on high-resolution (e.g., 1024 \times 1024 images) 2D synthetic and real data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KimYaoZhuChen2025_barycenter-nonconvex-concave</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kim, Kaheon and Yao, Rentian and Zhu, Changbo and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal transport barycenter via nonconvex concave minimax optimization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="JXYCYC2025_HOTET" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Embedding Empirical Distributions for Computing Optimal Transport Maps</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://jiangmingchen.top/" target="_blank" rel="noopener noreferrer">Mingchen Jiang</a>, <a href="https://francis-hsu.github.io/" target="_blank" rel="noopener noreferrer">Peng Xu</a>, Xichen Ye, <em>Xiaohui Chen</em>, <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>, and <a href="https://ychen-stat-ml.github.io/" target="_blank" rel="noopener noreferrer">Yifan Chen</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE International Symposium on Information Theory (ISIT)</em> Jun 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2504.17740" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/jiangmingchen/HOTET" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Distributional data have become increasingly prominent in modern signal processing, highlighting the necessity of computing optimal transport (OT) maps across multiple probability distributions. Nevertheless, recent studies on neural OT methods predominantly focused on the efficient computation of a single map between two distributions. To address this challenge, we introduce a novel approach to learning transport maps for new empirical distributions. Specifically, we employ the transformer architecture to produce embeddings from distributional data of varying length; these embeddings are then fed into a hypernetwork to generate neural OT maps. Various numerical experiments were conducted to validate the embeddings and the generated OT maps. The model implementation and the code are provided on this https URL https://github.com/jiangmingchen/HOTET</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">JXYCYC2025_HOTET</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jiang, Mingchen and Xu, Peng and Ye, Xichen and Chen, Xiaohui and Yang, Yun and Chen, Yifan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Symposium on Information Theory (ISIT)}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2025-04-20 16:00:41 -0700}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Embedding Empirical Distributions for Computing Optimal Transport Maps}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">arXiv</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="YNCY2025_snapshot-learning" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Density Evolution from Snapshot Data</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/rentianyao/" target="_blank" rel="noopener noreferrer">Rentian Yao</a>, <a href="https://sites.google.com/site/atsushinitanda" target="_blank" rel="noopener noreferrer">Atsushi Nitanda</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            Feb 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2502.17738" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Motivated by learning dynamical structures from static snapshot data, this paper presents a distribution-on-scalar regression approach for estimating the density evolution of a stochastic process from its noisy temporal point clouds. We propose an entropy-regularized nonparametric maximum likelihood estimator (E-NPMLE), which leverages the entropic optimal transport as a smoothing regularizer for the density flow. We show that the E-NPMLE has almost dimension-free statistical rates of convergence to the ground truth distributions, which exhibit a striking phase transition phenomenon in terms of the number of snapshots and per-snapshot sample size. To efficiently compute the E-NPMLE, we design a novel particle-based and grid-free coordinate KL divergence gradient descent (CKLGD) algorithm and prove its polynomial iteration complexity. Moreover, we provide numerical evidence on synthetic data to support our theoretical findings. This work contributes to the theoretical understanding and practical computation of estimating density evolution from noisy observations in arbitrary dimensions.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">YNCY2025_snapshot-learning</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Rentian and Nitanda, Atsushi and Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Learning Density Evolution from Snapshot Data}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">arXiv</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ZhuChen2025_convergence-nonconvex" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Convergence analysis of the Wasserstein proximal algorithm beyond geodesic convexity</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://one-punch24.github.io/" target="_blank" rel="noopener noreferrer">Shuailong Zhu</a>, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            Jan 2025
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2501.14993" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/One-punch24/Convergence-Analysis-of-WPA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The proximal algorithm is a powerful tool to minimize nonlinear and nonsmooth functionals in a general metric space. Motivated by the recent progress in studying the training dynamics of the noisy gradient descent algorithm on two-layer neural networks in the mean-field regime, we provide in this paper a simple and self-contained analysis for the convergence of the general-purpose Wasserstein proximal algorithm without assuming geodesic convexity on the objective functional. Under a natural Wasserstein analog of the Euclidean Polyak-Łojasiewicz inequality, we show that the proximal algorithm achieves an unbiased and linear convergence rate. Our convergence rate improves upon existing rates of the proximal algorithm for solving Wasserstein gradient flows under strong geodesic convexity. We also extend our analysis to the inexact proximal algorithm for geodesically semiconvex objectives. In our numerical experiments, proximal training demonstrates a faster convergence rate than the noisy gradient descent algorithm on mean-field neural networks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">ZhuChen2025_convergence-nonconvex</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Shuailong and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Convergence analysis of the Wasserstein proximal algorithm beyond geodesic convexity}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="YaoChenYang2023_WPCG" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Wasserstein proximal coordinate gradient algorithms</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/rentianyao/" target="_blank" rel="noopener noreferrer">Rentian Yao</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of Machine Learning Research</em> May 2024
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2405.04628" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Motivated by approximation Bayesian computation using mean-field variational approximation and the computation of equilibrium in multi-species systems with cross-interaction, this paper investigates the composite geodesically convex optimization problem over multiple distributions. The objective functional under consideration is composed of a convex potential energy on a product of Wasserstein spaces and a sum of convex self-interaction and internal energies associated with each distribution. To efficiently solve this problem, we introduce the Wasserstein Proximal Coordinate Gradient (WPCG) algorithms with parallel, sequential and random update schemes. Under a quadratic growth (QC) condition that is weaker than the usual strong convexity requirement on the objective functional, we show that WPCG converges exponentially fast to the unique global optimum. In the absence of the QG condition, WPCG is still demonstrated to converge to the global optimal solution, albeit at a slower polynomial rate. Numerical results for both motivating examples are consistent with our theoretical findings.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">YaoChenYang2023_WPCG</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Rentian and Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2023-10-09 22:22:12 -0700}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2024-10-15 07:29:34 -0700}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{269}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-66}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wasserstein proximal coordinate gradient algorithms}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="GracykChen2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">GeONet: a neural operator for learning the Wasserstein geodesic</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://andrewgracyk.com/" target="_blank" rel="noopener noreferrer">Andrew Gracyk</a>, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Conference on Uncertainty in Artificial Intelligence (UAI)</em> Jul 2024
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2209.14440" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/agracyk2/GeONet" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Optimal transport (OT) offers a versatile framework to compare complex data distributions in a geometrically meaningful way. Traditional methods for computing the Wasserstein distance and geodesic between probability measures require mesh-dependent domain discretization and suffer from the curse-of-dimensionality. We present GeONet, a mesh-invariant deep neural operator network that learns the non-linear mapping from the input pair of initial and terminal distributions to the Wasserstein geodesic connecting the two endpoint distributions. In the offline training stage, GeONet learns the saddle point optimality conditions for the dynamic formulation of the OT problem in the primal and dual spaces that are characterized by a coupled PDE system. The subsequent inference stage is instantaneous and can be deployed for real-time predictions in the online learning setting. We demonstrate that GeONet achieves comparable testing accuracy to the standard OT solvers on a simulation example and the CIFAR-10 dataset with considerably reduced inference-stage computational cost by orders of magnitude.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">GracykChen2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gracyk, Andrew and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Uncertainty in Artificial Intelligence (UAI)}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{Creative Commons Attribution 4.0 International}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-09-30 08:37:46 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:51:01 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/ARXIV.2209.14440}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GeONet: a neural operator for learning the Wasserstein geodesic}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/ARXIV.2209.14440}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="zhang2023generative" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Generative quantum machine learning via denoising diffusion probabilistic models</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/bingzhi-zhang/" target="_blank" rel="noopener noreferrer">Bingzhi Zhang</a>, <a href="https://francis-hsu.github.io/" target="_blank" rel="noopener noreferrer">Peng Xu</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.usc.edu/zhuang/" target="_blank" rel="noopener noreferrer">Quntao Zhuang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Physical Review Letters</em> Jul 2024
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2310.05866" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Francis-Hsu/QuantGenMdl" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep generative models are key-enabling technology to computer vision, text generation, and large language models. Denoising diffusion probabilistic models (DDPMs) have recently gained much attention due to their ability to generate diverse and high-quality samples in many computer vision tasks, as well as to incorporate flexible model architectures and a relatively simple training scheme. Quantum generative models, empowered by entanglement and superposition, have brought new insight to learning classical and quantum data. Inspired by the classical counterpart, we propose the quantum denoising diffusion probabilistic model (QuDDPM) to enable efficiently trainable generative learning of quantum data. QuDDPM adopts sufficient layers of circuits to guarantee expressivity, while it introduces multiple intermediate training tasks as interpolation between the target distribution and noise to avoid barren plateau and guarantee efficient training. We provide bounds on the learning error and demonstrate QuDDPM’s capability in learning correlated quantum noise model, quantum many-body phases, and topological structure of quantum data. The results provide a paradigm for versatile and efficient quantum generative learning.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2023generative</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Bingzhi and Xu, Peng and Chen, Xiaohui and Zhuang, Quntao}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2023-10-09 22:08:13 -0700}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2024-01-31 18:03:04 -0800}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Physical Review Letters}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{quant-ph}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Generative quantum machine learning via denoising diffusion probabilistic models}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Oral</a></abbr>
</div>

  
        <!-- Entry bib key -->
        <div id="ZhuangChenYangZhang2023_NMF-BM" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/yubo-zhuang/" target="_blank" rel="noopener noreferrer">Yubo Zhuang</a>, <em>Xiaohui Chen</em>, <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>, and <a href="http://ryz.ece.illinois.edu/" target="_blank" rel="noopener noreferrer">Richard Y. Zhang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations (ICLR)</em> May 2024
          </div>
<span class="honor">
            Oral Presentation [One of 85/7262 submissions. Top 1.2%]
          </span><!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2305.18436" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Yubo02/Statistically-Optimal-K-means-Clustering-via-Nonnegative-Low-rank-Semidefinite-Programming" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>K-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the K-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed K-means formulation using a nonconvex Burer–Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves substantially smaller mis-clustering errors compared to the existing state-of-the-art.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ZhuangChenYangZhang2023_NMF-BM</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhuang, Yubo and Chen, Xiaohui and Yang, Yun and Zhang, Richard Y.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations (ICLR)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2023-06-04 11:47:33 -0700}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2024-01-16 21:35:09 -0800}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ChChWu2024" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Central limit theorems for high dimensional dependent data</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/site/bryanchangjinyuan/" target="_blank" rel="noopener noreferrer">Jinyuan Chang</a>, <em>Xiaohui Chen</em>, and Mingcong Wu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Bernoulli</em> May 2024
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2104.12929" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Motivated by statistical inference problems in high-dimensional time series data analysis, we first derive non-asymptotic error bounds for Gaussian approximations of sums of high-dimensional dependent random vectors on hyper-rectangles, simple convex sets and sparsely convex sets. We investigate the quantitative effect of temporal dependence on the rates of convergence to a Gaussian random vector over three different dependency frameworks (α-mixing, m-dependent, and physical dependence measure). In particular, we establish new error bounds under the α-mixing framework and derive faster rate over existing results under the physical dependence measure. To implement the proposed results in practical statistical inference problems, we also derive a data-driven parametric bootstrap procedure based on a kernel estimator for the long-run covariance matrices. We apply the unified Gaussian and bootstrap approximation results to test mean vectors with combined \ell^2 and \ell^∞type statistics, change point detection, and construction of confidence regions for covariance and precision matrices, all for time series data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ChChWu2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chang, Jinyuan and Chen, Xiaohui and Wu, Mingcong}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2023-11-11 11:38:48 -0800}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2023-11-11 11:39:04 -0800}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3150/23-BEJ1614}</span><span class="p">,</span>
  <span class="na">fjournal</span> <span class="p">=</span> <span class="s">{Bernoulli}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1350-7265}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Bernoulli}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{712-742}</span><span class="p">,</span>
  <span class="na">sici</span> <span class="p">=</span> <span class="s">{1350-7265(2024)30:1&lt;712:CLTFHD&gt;2.0.CO;2-L}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Central limit theorems for high dimensional dependent data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3150/23-BEJ1614}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.3150/22-BEJ1459" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Stratified incomplete local simplex tests for curvature of nonparametric multiple regression</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/yangleisong/" target="_blank" rel="noopener noreferrer">Yanglei Song</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/kkatostat/home/" target="_blank" rel="noopener noreferrer">Kengo Kato</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Bernoulli</em> May 2023
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2003.09091" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/ysong44/Stratified-incomplete-local-simplex-tests" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Principled nonparametric tests for regression curvature in Rd are often statistically and computationally challenging. This paper introduces the stratified incomplete local simplex (SILS) tests for joint concavity of nonparametric multiple regression. The SILS tests with suitable bootstrap calibration are shown to achieve simultaneous guarantees on dimension-free computational complexity, polynomial decay of the uniform error-in-size, and power consistency for general (global and local) alternatives. To establish these results, we develop a general theory for incomplete U-processes with stratified random sparse weights. Novel technical ingredients include maximal inequalities for the supremum of multiple incomplete U-processes.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.3150/22-BEJ1459</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Song, Yanglei and Chen, Xiaohui and Kato, Kengo}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-10-14 07:31:27 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-10-14 07:31:27 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3150/22-BEJ1459}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Bernoulli}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{curvature testing, incomplete U-processes, Nonparametric regression, stratification}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{323 -- 349}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Bernoulli Society for Mathematical Statistics and Probability}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Stratified incomplete local simplex tests for curvature of nonparametric multiple regression}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3150/22-BEJ1459}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3150/22-BEJ1459}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ZhuangChenYang2022_LA-SDP" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Likelihood adjusted semidefinite programs for clustering heterogeneous data</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/yubo-zhuang/" target="_blank" rel="noopener noreferrer">Yubo Zhuang</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Machine Learning (ICML)</em> May 2023
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2209.15097" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Clustering is a widely deployed unsupervised learning tool. Model-based clustering is a flexible framework to tackle data heterogeneity when the clusters have different shapes. Likelihood-based inference for mixture distributions often involves non-convex and high-dimensional objective functions, imposing difficult computational and statistical challenges. The classic expectation-maximization (EM) algorithm is a computationally thrifty iterative method that maximizes a surrogate function minorizing the log-likelihood of observed data in each iteration, which however suffers from bad local maxima even in the special case of the standard Gaussian mixture model with common isotropic covariance matrices. On the other hand, recent studies reveal that the unique global solution of a semidefinite programming (SDP) relaxed K-means achieves the information-theoretically sharp threshold for perfectly recovering the cluster labels under the standard Gaussian mixture model. In this paper, we extend the SDP approach to a general setting by integrating cluster labels as model parameters and propose an iterative likelihood adjusted SDP (iLA-SDP) method that directly maximizes the \emphexact observed likelihood in the presence of data heterogeneity. By lifting the cluster assignment to group-specific membership matrices, iLA-SDP avoids centroids estimation – a key feature that allows exact recovery under well-separateness of centroids without being trapped by their adversarial configurations. Thus iLA-SDP is less sensitive than EM to initialization and more stable on high-dimensional data. Our numeric experiments demonstrate that iLA-SDP can achieve lower mis-clustering errors over several widely used clustering methods including K-means, SDP and EM algorithms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ZhuangChenYang2022_LA-SDP</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhuang, Yubo and Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning (ICML)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-10-02 19:51:13 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2023-04-24 19:05:06 -0500}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Machine Learning (stat.ML), Machine Learning (cs.LG), Optimization and Control (math.OC), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Likelihood adjusted semidefinite programs for clustering heterogeneous data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.48550/ARXIV.2209.15097}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ZhuangChenYang2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Wasserstein K-means for clustering probability distributions</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/yubo-zhuang/" target="_blank" rel="noopener noreferrer">Yubo Zhuang</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS)</em> May 2022
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2209.06975" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Yubo02/Wasserstein-K-means-for-clustering-probability-distributions" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Clustering is an important exploratory data analysis technique to group objects based on their similarity. The widely used K-means clustering method relies on some notion of distance to partition data into a fewer number of groups. In the Euclidean space, centroid-based and distance-based formulations of the K-means are equivalent. In modern machine learning applications, data often arise as probability distributions and a natural generalization to handle measure-valued data is to use the optimal transport metric. Due to non-negative Alexandrov curvature of the Wasserstein space, barycenters suffer from regularity and non-robustness issues. The peculiar behaviors of Wasserstein barycenters may make the centroid-based formulation fail to represent the within-cluster data points, while the more direct distance-based K-means approach and its semidefinite program (SDP) relaxation are capable of recovering the true cluster labels. In the special case of clustering Gaussian distributions, we show that the SDP relaxed Wasserstein K-means can achieve exact recovery given the clusters are well-separated under the 2-Wasserstein metric. Our simulation and real data examples also demonstrate that distance-based K-means can achieve better classification performance over the standard centroid-based K-means for clustering probability distributions and images.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ZhuangChenYang2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhuang, Yubo and Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-09-14 20:28:06 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 09:00:11 -0500}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wasserstein $K$-means for clustering probability distributions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="pmlr-v178-yao22a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Mean-field nonparametric estimation of interacting particle systems</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/rentianyao/" target="_blank" rel="noopener noreferrer">Rentian Yao</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of Thirty Fifth Conference on Learning Theory (COLT)</em> 02–05 jul 2022
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2205.07937" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper concerns the nonparametric estimation problem of the distribution-state dependent drift vector field in an interacting N-particle system. Observing single-trajectory data for each particle, we derive the mean-field rate of convergence for the maximum likelihood estimator (MLE), which depends on both Gaussian complexity and Rademacher complexity of the function class. In particular, when the function class contains α-smooth Hölder functions, our rate of convergence is minimax optimal on the order of N^-\fracαd+2α. Combining with a Fourier analytical deconvolution estimator, we derive the consistency of MLE for the external force and interaction kernel in the McKean-Vlasov equation.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v178-yao22a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yao, Rentian and Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of Thirty Fifth Conference on Learning Theory (COLT)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:57:33 -0500}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Loh, Po-Ling and Raginsky, Maxim}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{02--05 Jul}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2242--2275}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mean-field nonparametric estimation of interacting particle systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{178}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="pmlr-v151-zhuang22a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sketch-and-lift: scalable subsampled semidefinite program for K-means clustering</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/yubo-zhuang/" target="_blank" rel="noopener noreferrer">Yubo Zhuang</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of The 25th International Conference on Artificial Intelligence and Statistics (AISTATS)</em> 28–30 mar 2022
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2201.08226" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/Yubo02/Sketch-and-Lift-Scalable-Subsampled-Semidefinite-Program-for-K-means-Clustering" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p> Semidefinite programming (SDP) is a powerful tool for tackling a wide range of computationally hard problems such as clustering. Despite the high accuracy, semidefinite programs are often too slow in practice with poor scalability on large (or even moderate) datasets. In this paper, we introduce a linear time complexity algorithm for approximating an SDP relaxed K-means clustering. The proposed sketch-and-lift (SL) approach solves an SDP on a subsampled dataset and then propagates the solution to all data points by a nearest-centroid rounding procedure. It is shown that the SL approach enjoys a similar exact recovery threshold as the K-means SDP on the full dataset, which is known to be information-theoretically tight under the Gaussian mixture model. The SL method can be made adaptive with enhanced theoretic properties when the cluster sizes are unbalanced. Our simulation experiments demonstrate that the statistical accuracy of the proposed method outperforms state-of-the-art fast clustering algorithms without sacrificing too much computational efficiency, and is comparable to the original K-means SDP with substantially reduced runtime. </p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v151-zhuang22a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhuang, Yubo and Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 25th International Conference on Artificial Intelligence and Statistics (AISTATS)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:39:43 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:59:39 -0500}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{28--30 Mar}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9214--9246}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Sketch-and-lift: scalable subsampled semidefinite program for K-means clustering}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{151}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ParkChenSimpons2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Robust Inference for Partially Observed Functional Response Data</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://business.utsa.edu/faculty/yeonjoo-park-ph-d/" target="_blank" rel="noopener noreferrer">Yeonjoo Park</a>, <em>Xiaohui Chen</em>, and <a href="http://publish.illinois.edu/dgsimpson/" target="_blank" rel="noopener noreferrer">Douglas Simpson</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Statistica Sinica</em> 28–30 mar 2022
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2002.08560" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Irregular functional data in which densely sampled curves are observed over different ranges pose a challenge for modeling and inference, and sensitivity to outlier curves is a concern in applications. Motivated by applications in quantitative ultrasound signal analysis, this paper investigates a class of robust M-estimators for partially observed functional data including functional location and quantile estimators. Consistency of the estimators is established under general conditions on the partial observation process. Under smoothness conditions on the class of M-estimators, asymptotic Gaussian process approximations are established and used for large sample inference. The large sample approximations justify a bootstrap approximation for robust inferences about the functional response process. The performance is demonstrated in simulations and in the analysis of irregular functional data from quantitative ultrasound analysis.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ParkChenSimpons2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Park, Yeonjoo and Chen, Xiaohui and Simpson, Douglas}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:59:06 -0500}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Statistica Sinica}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2265-2293}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robust Inference for Partially Observed Functional Response Data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{32}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/21-EJS1915" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A robust bootstrap change point test for high-dimensional location parameter</div>
          <!-- Author -->
          <div class="author">
          

          Mengjia Yu, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Electronic Journal of Statistics</em> 28–30 mar 2022
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1904.03372" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We consider the problem of change point detection for high-dimensional distributions in a location family when the dimension can be much larger than the sample size. In change point analysis, the widely used cumulative sum (CUSUM) statistics are sensitive to outliers and heavy-tailed distributions. In this paper, we propose a robust, tuning-free (i.e., fully data-dependent), and easy-to-implement change point test that enjoys strong theoretical guarantees. To achieve the robust purpose in a nonparametric setting, we formulate the change point detection in the multivariate U-statistics framework with anti-symmetric and nonlinear kernels. Specifically, the within-sample noise is canceled out by anti-symmetry of the kernel, while the signal distortion under certain nonlinear kernels can be controlled such that the between-sample change point signal is magnitude preserving. A (half) jackknife multiplier bootstrap (JMB) tailored to the change point detection setting is proposed to calibrate the distribution of our ℓ∞-norm aggregated test statistic. Subject to mild moment conditions on kernels, we derive the uniform rates of convergence for the JMB to approximate the sampling distribution of the test statistic, and analyze its size and power properties. Extensions to multiple change point testing and estimation are discussed with illustration from numerical studies.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/21-EJS1915</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Mengjia and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:54:34 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:52:14 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/21-EJS1915}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Electronic Journal of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{bootstrap, Change point analysis, Gaussian approximation, High-dimensional data, U-statistics}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1096 -- 1152}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics and Bernoulli Society}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{A robust bootstrap change point test for high-dimensional location parameter}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/21-EJS1915}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/21-EJS1915}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="9366690" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Cutoff for Exact Recovery of Gaussian Mixture Models</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Information Theory</em> Jun 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2001.01194" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We determine the information-theoretic cutoff value on separation of cluster centers for exact recovery of cluster labels in a K-component Gaussian mixture model with equal cluster sizes. Moreover, we show that a semidefinite programming (SDP) relaxation of the K-means clustering method achieves such sharp threshold for exact recovery without assuming the symmetry of cluster centers.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">9366690</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:07:29 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:53:58 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TIT.2021.3063155}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1557-9654}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Information Theory}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4223-4238}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cutoff for Exact Recovery of Gaussian Mixture Models}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{67}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TIT.2021.3063155}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="CHEN2021303" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Diffusion K-means clustering on manifolds: Provable exact recovery via semidefinite relaxations</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Applied and Computational Harmonic Analysis</em> May 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1903.04416" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/xiaohuichen88/Diffusion-Kmeans" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce the diffusion K-means clustering method on Riemannian submanifolds, which maximizes the within-cluster connectedness based on the diffusion distance. The diffusion K-means constructs a random walk on the similarity graph with vertices as data points randomly sampled on the manifolds and edges as similarities given by a kernel that captures the local geometry of manifolds. The diffusion K-means is a multi-scale clustering tool that is suitable for data with non-linear and non-Euclidean geometric features in mixed dimensions. Given the number of clusters, we propose a polynomial-time convex relaxation algorithm via the semidefinite programming (SDP) to solve the diffusion K-means. In addition, we also propose a nuclear norm regularized SDP that is adaptive to the number of clusters. In both cases, we show that exact recovery of the SDPs for diffusion K-means can be achieved under suitable between-cluster separability and within-cluster connectedness of the submanifolds, which together quantify the hardness of the manifold clustering problem. We further propose the localized diffusion K-means by using the local adaptive bandwidth estimated from the nearest neighbors. We show that exact recovery of the localized diffusion K-means is fully adaptive to the local probability density and geometric structures of the underlying submanifolds.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CHEN2021303</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:54:12 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.acha.2020.03.002}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1063-5203}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Applied and Computational Harmonic Analysis}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Manifold clustering, K-means, Riemannian submanifolds, Diffusion distance, Semidefinite programming, Random walk on random graphs, Laplace-Beltrami operator, Mixing times, Adaptivity}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{303-347}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusion K-means clustering on manifolds: Provable exact recovery via semidefinite relaxations}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S106352032030021X}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{52}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S106352032030021X}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.acha.2020.03.002}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="https://doi.org/10.1111/rssb.12406" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Finite sample change point inference and identification for high-dimensional mean vectors</div>
          <!-- Author -->
          <div class="author">
          

          Mengjia Yu, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> Apr 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1711.08747" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Abstract Cumulative sum (CUSUM) statistics are widely used in the change point inference and identification. For the problem of testing for existence of a change point in an independent sample generated from the mean-shift model, we introduce a Gaussian multiplier bootstrap to calibrate critical values of the CUSUM test statistics in high dimensions. The proposed bootstrap CUSUM test is fully data dependent and it has strong theoretical guarantees under arbitrary dependence structures and mild moment conditions. Specifically, we show that with a boundary removal parameter the bootstrap CUSUM test enjoys the uniform validity in size under the null and it achieves the minimax separation rate under the sparse alternatives when the dimension p can be larger than the sample size n. Once a change point is detected, we estimate the change point location by maximising the ℓ∞-norm of the generalised CUSUM statistics at two different weighting scales corresponding to covariance stationary and non-stationary CUSUM statistics. For both estimators, we derive their rates of convergence and show that dimension impacts the rates only through logarithmic factors, which implies that consistency of the CUSUM estimators is possible when p is much larger than n. In the presence of multiple change points, we propose a principled bootstrap-assisted binary segmentation (BABS) algorithm to dynamically adjust the change point detection rule and recursively estimate their locations. We derive its rate of convergence under suitable signal separation and strength conditions. The results derived in this paper are non-asymptotic and we provide extensive simulation studies to assess the finite sample performance. The empirical evidence shows an encouraging agreement with our theoretical results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">https://doi.org/10.1111/rssb.12406</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yu, Mengjia and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:16:32 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:54:35 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/rssb.12406}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{binary segmentation, bootstrap, CUSUM, change point analysis, Gaussian approximation, high-dimensional data}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{247-270}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Finite sample change point inference and identification for high-dimensional mean vectors}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12406}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{83}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12406}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/rssb.12406}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.3150/20-BEJ1251" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Hanson–Wright inequality in Hilbert spaces with application to K-means clustering for non-Euclidean data</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/yunyangstat/" target="_blank" rel="noopener noreferrer">Yun Yang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Bernoulli</em> Apr 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1810.11180" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We derive a dimension-free Hanson–Wright inequality for quadratic forms of independent sub-gaussian random variables in a separable Hilbert space. Our inequality is an infinite-dimensional generalization of the classical Hanson–Wright inequality for finite-dimensional Euclidean random vectors. We illustrate an application to the generalized K-means clustering problem for non-Euclidean data. Specifically, we establish the exponential rate of convergence for a semidefinite relaxation of the generalized K-means, which together with a simple rounding algorithm imply the exact recovery of the true clustering structure.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.3150/20-BEJ1251</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Yang, Yun}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:14:30 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:55:19 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3150/20-BEJ1251}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Bernoulli}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{$k$-means, Hanson--Wright inequality, Hilbert space, semidefinite relaxation}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{586 -- 614}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Bernoulli Society for Mathematical Statistics and Probability}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Hanson--Wright inequality in Hilbert spaces with application to $K$-means clustering for non-Euclidean data}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3150/20-BEJ1251}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{27}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3150/20-BEJ1251}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/21-ECP416" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Maximum likelihood estimation of potential energy in interacting particle systems from single-trajectory data</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Electronic Communications in Probability</em> Jul 2021
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2007.11048" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper concerns the parameter estimation problem for the quadratic potential energy in interacting particle systems from continuous-time and single-trajectory data. Even though such dynamical systems are high-dimensional, we show that the vanilla maximum likelihood estimator (without regularization) is able to estimate the interaction potential parameter with optimal rate of convergence simultaneously in mean-field limit and in long-time dynamics. This to some extend avoids the curse-of-dimensionality for estimating large dynamical systems under symmetry of the particle interaction.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/21-ECP416</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:10:53 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:55:46 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/21-ECP416}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Electronic Communications in Probability}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{interacting particle systems, maximum likelihood estimation, mean-field regime, stochastic Vlasov equation, symmetry}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{none}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1 -- 13}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics and Bernoulli Society}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Maximum likelihood estimation of potential energy in interacting particle systems from single-trajectory data}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/21-ECP416}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{26}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/21-ECP416}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ChenKato2020_PTRF" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Jackknife multiplier bootstrap: finite sample approximations to the U-process supremum with applications</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/kkatostat/home/" target="_blank" rel="noopener noreferrer">Kengo Kato</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Probability Theory and Related Fields</em> Jul 2020
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1708.02705" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper is concerned with finite sample approximations to the supremum of a non-degenerate U-process of a general order indexed by a function class. We are primarily interested in situations where the function class as well as the underlying distribution change with the sample size, and the U-process itself is not weakly convergent as a process. Such situations arise in a variety of modern statistical problems. We first consider Gaussian approximations, namely, approximate the U-process supremum by the supremum of a Gaussian process, and derive coupling and Kolmogorov distance bounds. Such Gaussian approximations are, however, not often directly applicable in statistical problems since the covariance function of the approximating Gaussian process is unknown. This motivates us to study bootstrap-type approximations to the U-process supremum. We propose a novel jackknife multiplier bootstrap (JMB) tailored to the U-process, and derive coupling and Kolmogorov distance bounds for the proposed JMB method. All these results are non-asymptotic, and established under fairly general conditions on function classes and underlying distributions. Key technical tools in the proofs are new local maximal inequalities for U-processes, which may be useful in other problems. We also discuss applications of the general approximation results to testing for qualitative features of nonparametric functions based on generalized local U-processes.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ChenKato2020_PTRF</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Kato, Kengo}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:55:34 -0500}</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{31}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s00440-019-00936-y}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1432-2064}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Probability Theory and Related Fields}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1097--1163}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Jackknife multiplier bootstrap: finite sample approximations to the U-process supremum with applications}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s00440-019-00936-y}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{176}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s00440-019-00936-y}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">arXiv</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="https://doi.org/10.48550/arxiv.2002.09484" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A note on Stein equation for weighted sums of independent χ^2 distributions</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://faculty.math.illinois.edu/~psdey/" target="_blank" rel="noopener noreferrer">Partha Dey</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            Jul 2020
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/2002.09484" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex">  <span class="c">author = {Chen, Xiaohui and Dey, Partha},</span>
  <span class="c">copyright = {arXiv.org perpetual, non-exclusive license},</span>
  <span class="c">date-added = {2022-08-29 18:18:01 -0500},</span>
  <span class="c">date-modified = {2022-09-30 08:52:07 -0500},</span>
  <span class="c">doi = {10.48550/ARXIV.2002.09484},</span>
  <span class="c">keywords = {Probability (math.PR), Statistics Theory (math.ST), FOS: Mathematics, FOS: Mathematics},</span>
  <span class="c">publisher = {arXiv},</span>
  <span class="c">title = {A note on Stein equation for weighted sums of independent $χ^{2}$ distributions},</span>
  <span class="c">year = {2020},</span>
  <span class="c">bdsk-url-2 = {https://doi.org/10.48550/ARXIV.2002.09484}</span>
<span class="c">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Lecture Notes</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="chen2020_geometricflows" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Geometric Flows for Applied Mathematician.</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            Jul 2020
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a href="/assets/pdf/geometric_flows.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">In Book</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="ChenQiu2020_cepr" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Scenario analysis of non-pharmaceutical interventions on global COVID-19 transmissions.</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and Ziyi Qiu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Covid Economics: Vetted and Real-Time Papers, Centre for Economic Policy Research (CEPR)</em> Jul 2020
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://cepr.org/voxeu/columns/covid-19-government-interventions-and-economy" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Media</a>
            <a href="https://arxiv.org/abs/2004.04529" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper introduces a dynamic panel SIR (DP-SIR) model to investigate the impact of non-pharmaceutical interventions (NPIs) on the COVID-19 transmission dynamics with panel data from 9 countries across the globe. By constructing scenarios with different combinations of NPIs, our empirical findings suggest that countries may avoid the lockdown policy with imposing school closure, mask wearing and centralized quarantine to reach similar outcomes on controlling the COVID-19 infection. Our results also suggest that, as of April 4th, 2020, certain countries such as the U.S. and Singapore may require additional measures of NPIs in order to control disease transmissions more effectively, while other countries may cautiously consider to gradually lift some NPIs to mitigate the costs to the overall economy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ChenQiu2020_cepr</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Qiu, Ziyi}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:59:12 -0500}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Covid Economics: Vetted and Real-Time Papers, Centre for Economic Policy Research (CEPR)}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{46-67}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Scenario analysis of non-pharmaceutical interventions on global COVID-19 transmissions.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="XuChenWu2020_entropy" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Estimation of Dynamic Networks for High-Dimensional Nonstationary Time Series</div>
          <!-- Author -->
          <div class="author">
          

          Mengyu Xu, <em>Xiaohui Chen</em>, and <a href="https://www.stat.uchicago.edu/~wbwu/" target="_blank" rel="noopener noreferrer">Wei Biao Wu</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Entropy</em> Jul 2020
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1911.06385" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper is concerned with the estimation of time-varying networks for high-dimensional nonstationary time series. Two types of dynamic behaviors are considered: structural breaks (i.e., abrupt change points) and smooth changes. To simultaneously handle these two types of time-varying features, a two-step approach is proposed: multiple change point locations are first identified on the basis of comparing the difference between the localized averages on sample covariance matrices, and then graph supports are recovered on the basis of a kernelized time-varying constrained     L 1    -minimization for inverse matrix estimation (CLIME) estimator on each segment. We derive the rates of convergence for estimating the change points and precision matrices under mild moment and dependence conditions. In particular, we show that this two-step approach is consistent in estimating the change points and the piecewise smooth precision matrix function, under a certain high-dimensional scaling limit. The method is applied to the analysis of network structure of the S&amp;P 500 index between 2003 and 2008.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">XuChenWu2020_entropy</span><span class="p">,</span>
  <span class="na">article-number</span> <span class="p">=</span> <span class="s">{55}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Mengyu and Chen, Xiaohui and Wu, Wei Biao}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:54:27 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/e22010055}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1099-4300}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Entropy}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Estimation of Dynamic Networks for High-Dimensional Nonstationary Time Series}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/1099-4300/22/1/55}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{22}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://www.mdpi.com/1099-4300/22/1/55}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3390/e22010055}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">In Book</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="doi:https://doi.org/10.1002/9781118445112.stat05986.pub2" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">U-Statistics</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            Jul 2019
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/stat05986_ustat.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Abstract A U-statistic, calculated from a random sample of size n, is an average of a symmetric function calculated for all m-tuples in the sample. Examples include the sample variance, the Cramér-von Mises and energy statistics of goodness-of-fit, and the Kaplan–Meier and Nelson–Aalen estimators in survival analysis. Asymptotic properties are described.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">doi:https://doi.org/10.1002/9781118445112.stat05986.pub2</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Wiley StatsRef: Statistics Reference Online}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 18:25:05 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 18:25:05 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1002/9781118445112.stat05986.pub2}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781118445112}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{random sample, sample variance, Cram{\'e}r-von Mises, Kaplan-Meier, Nelson-Aalen, energy statistic, asymptotics, bootstrap}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{John Wiley &amp; Sons, Ltd}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{U-Statistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat05986.pub2}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat05986.pub2}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1002/9781118445112.stat05986.pub2}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/19-EJS1643" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Approximating high-dimensional infinite-order U-statistics: Statistical and computational guarantees</div>
          <!-- Author -->
          <div class="author">
          

          <a href="https://sites.google.com/view/yangleisong/" target="_blank" rel="noopener noreferrer">Yanglei Song</a>, <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/kkatostat/home/" target="_blank" rel="noopener noreferrer">Kengo Kato</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Electronic Journal of Statistics</em> Jul 2019
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1901.01163" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We study the problem of distributional approximations to high-dimensional non-degenerate U-statistics with random kernels of diverging orders. Infinite-order U-statistics (IOUS) are a useful tool for constructing simultaneous prediction intervals that quantify the uncertainty of ensemble methods such as subbagging and random forests. A major obstacle in using the IOUS is their computational intractability when the sample size and/or order are large. In this article, we derive non-asymptotic Gaussian approximation error bounds for an incomplete version of the IOUS with a random kernel. We also study data-driven inferential methods for the incomplete IOUS via bootstraps and develop their statistical and computational guarantees.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/19-EJS1643</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Song, Yanglei and Chen, Xiaohui and Kato, Kengo}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:38:15 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:53:21 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/19-EJS1643}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Electronic Journal of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{bootstrap, Gaussian approximation, incomplete $U$ statistics, Infinite-order $U$-statistics, random forests, uncertainty quantification}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4794 -- 4848}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics and Bernoulli Society}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Approximating high-dimensional infinite-order $U$-statistics: Statistical and computational guarantees}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/19-EJS1643}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/19-EJS1643}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/18-AOS1773" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Randomized incomplete U-statistics in high dimensions</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://sites.google.com/site/kkatostat/home/" target="_blank" rel="noopener noreferrer">Kengo Kato</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The Annals of Statistics</em> Jul 2019
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1712.00771" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper studies inference for the mean vector of a high-dimensional U-statistic. In the era of big data, the dimension d of the U-statistic and the sample size n of the observations tend to be both large, and the computation of the U-statistic is prohibitively demanding. Data-dependent inferential procedures such as the empirical bootstrap for U-statistics is even more computationally expensive. To overcome such a computational bottleneck, incomplete U-statistics obtained by sampling fewer terms of the U-statistic are attractive alternatives. In this paper, we introduce randomized incomplete U-statistics with sparse weights whose computational cost can be made independent of the order of the U-statistic. We derive nonasymptotic Gaussian approximation error bounds for the randomized incomplete U-statistics in high dimensions, namely in cases where the dimension d is possibly much larger than the sample size n, for both nondegenerate and degenerate kernels. In addition, we propose generic bootstrap methods for the incomplete U-statistics that are computationally much less demanding than existing bootstrap methods, and establish finite sample validity of the proposed bootstrap methods. Our methods are illustrated on the application to nonparametric testing for the pairwise independence of a high-dimensional random vector under weaker assumptions than those appearing in the literature.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/18-AOS1773</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Kato, Kengo}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:34:05 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:57:52 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/18-AOS1773}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Annals of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Bernoulli sampling, bootstrap, Divide and conquer, Gaussian approximation, incomplete $U$-statistics, randomized inference, sampling with replacement}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3127 -- 3156}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Randomized incomplete $U$-statistics in high dimensions}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/18-AOS1773}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{47}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/18-AOS1773}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.2307/26384241" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Inference of high-dimensional linear models with time-varying coefficients</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and Yifeng He</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Statistica Sinica</em> Jul 2018
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1506.03909" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose a pointwise inference algorithm for high-dimensional linear models with time-varying coefficients. The method is based on a novel combination of the nonparametric kernel smoothing technique and a Lasso bias-corrected ridge regression estimator. Due to the non-stationarity feature of the model, dynamic bias-variance decomposition of the estimator is obtained. With a bias-correction procedure, the local null distribution of the estimator of the time-varying coefficient vector is characterized for iid Gaussian and heavy-tailed errors. The limiting null distribution is also established for Gaussian process errors, and we show that the asymptotic properties differ between short-range and long-range dependent errors. Here, p-values are adjusted by a Bonferroni-type correction procedure to control the familywise error rate (FWER) in the asymptotic sense at each time point. The finite sample size performance of the proposed inference algorithm is illustrated with synthetic data and an application to learn brain connectivity by using the resting-state fMRI data for Parkinson’s disease.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.2307/26384241</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and He, Yifeng}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:49:09 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:55:26 -0500}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{10170405, 19968507}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Statistica Sinica}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{255--276}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Statistical Science, Academia Sinica}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inference of high-dimensional linear models with time-varying coefficients}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.jstor.org/stable/26384241}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2022-08-29}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{28}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{http://www.jstor.org/stable/26384241}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/17-AOS1563" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Gaussian and bootstrap approximations for high-dimensional U-statistics and their applications</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The Annals of Statistics</em> Jul 2018
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1610.00032" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper studies the Gaussian and bootstrap approximations for the probabilities of a nondegenerate U-statistic belonging to the hyperrectangles in \mathbbR^d when the dimension d is large. A two-step Gaussian approximation procedure that does not impose structural assumptions on the data distribution is proposed. Subject to mild moment conditions on the kernel, we establish the explicit rate of convergence uniformly in the class of all hyperrectangles in \mathbbR^d that decays polynomially in sample size for a high-dimensional scaling limit, where the dimension can be much larger than the sample size. We also provide computable approximation methods for the quantiles of the maxima of centered U-statistics. Specifically, we provide a unified perspective for the empirical bootstrap, the randomly reweighted bootstrap and the Gaussian multiplier bootstrap with the jackknife estimator of covariance matrix as randomly reweighted quadratic forms and we establish their validity. We show that all three methods are inferentially first-order equivalent for high-dimensional U-statistics in the sense that they achieve the same uniform rate of convergence over all d-dimensional hyperrectangles. In particular, they are asymptotically valid when the dimension d can be as large as O(e^n^c) for some constant c∈(0,1/7). The bootstrap methods are applied to statistical applications for high-dimensional non-Gaussian data including: (i) principled and data-dependent tuning parameter selection for regularized estimation of the covariance matrix and its related functionals; (ii) simultaneous inference for the covariance and rank correlation matrices. In particular, for the thresholded covariance matrix estimator with the bootstrap selected tuning parameter, we show that for a class of sub-Gaussian data, error bounds of the bootstrapped thresholded covariance matrix estimator can be much tighter than those of the minimax estimator with a universal threshold. In addition, we also show that the Gaussian-like convergence rates can be achieved for heavy-tailed data, which are less conservative than those obtained by the Bonferroni technique that ignores the dependency in the underlying data distribution.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/17-AOS1563</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 10:35:00 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:54:48 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/17-AOS1563}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Annals of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{bootstrap, Gaussian approximation, high-dimensional inference, U-statistics}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{642 -- 678}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Gaussian and bootstrap approximations for high-dimensional U-statistics and their applications}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/17-AOS1563}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{46}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/17-AOS1563}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/17-EJS1325" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Sparse transition matrix estimation for high-dimensional and locally stationary vector autoregressive models</div>
          <!-- Author -->
          <div class="author">
          

          Xin Ding, Ziyi Qiu, and <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Electronic Journal of Statistics</em> Jul 2017
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1604.04002" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/UBCDingXin/TVVAR" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We consider the estimation of the transition matrix in the high-dimensional time-varying vector autoregression (TV-VAR) models. Our model builds on a general class of locally stationary VAR processes that evolve smoothly in time. We propose a hybridized kernel smoothing and \ell^1-regularized method to directly estimate the sequence of time-varying transition matrices. Under the sparsity assumption on the transition matrix, we establish the rate of convergence of the proposed estimator and show that the convergence rate depends on the smoothness of the locally stationary VAR processes only through the smoothness of the transition matrix function. In addition, for our estimator followed by thresholding, we prove that the false positive rate (type I error) and false negative rate (type II error) in the pattern recovery can asymptotically vanish in the presence of weak signals without assuming the minimum nonzero signal strength condition. Favorable finite sample performances over the \ell^2-penalized least-squares estimator and the unstructured maximum likelihood estimator are shown on simulated data. We also provide two real examples on estimating the dependence structures on financial stock prices and economic exchange rates datasets.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/17-EJS1325</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ding, Xin and Qiu, Ziyi and Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:47:01 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:59:47 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/17-EJS1325}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Electronic Journal of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{high-dimension, kernel smoothing, Locally stationary processes, Sparsity, time-varying parameters, vector autoregression}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3871 -- 3902}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics and Bernoulli Society}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Sparse transition matrix estimation for high-dimensional and locally stationary vector autoregressive models}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/17-EJS1325}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/17-EJS1325}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="7558216" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Regularized Estimation of Linear Functionals of Precision Matrices for High-Dimensional Time Series</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, Mengyu Xu, and <a href="https://www.stat.uchicago.edu/~wbwu/" target="_blank" rel="noopener noreferrer">Wei Biao Wu</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Signal Processing</em> Dec 2016
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1506.03832" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper studies a Dantzig-selector type regularized estimator for linear functionals of high-dimensional linear processes. Explicit rates of convergence of the proposed estimator are obtained and they cover the broad regime from independent identically distributed samples to long-range dependent time series and from sub-Gaussian innovations to those with mild polynomial moments. It is shown that the convergence rates depend on the degree of temporal dependence and the moment conditions of the underlying linear processes. The Dantzig-selector estimator is applied to the sparse Markowitz portfolio allocation and the optimal linear prediction for time series, in which the ratio consistency when compared with an oracle estimator is established. The effect of dependence and innovation moment conditions is further illustrated in the simulation study. Finally, the regularized estimator is applied to classify the cognitive states on a real functional magnetic resonance imaging dataset and to portfolio optimization on a financial dataset.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">7558216</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Xu, Mengyu and Wu, Wei Biao}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:45:36 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:58:01 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TSP.2016.2605079}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1941-0476}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Signal Processing}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6459-6470}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Regularized Estimation of Linear Functionals of Precision Matrices for High-Dimensional Time Series}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{64}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TSP.2016.2605079}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">In Book</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/15-EJS1007" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Discussion of “High-dimensional autocovariance matrices and optimal linear prediction”</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Electronic Journal of Statistics</em> Dec 2015
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/15-EJS1007</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 18:30:04 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 18:30:04 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/15-EJS1007}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Electronic Journal of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Optimal linear predition, shrinkage, Sparsity}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{801 -- 810}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics and Bernoulli Society}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Discussion of ``High-dimensional autocovariance matrices and optimal linear prediction''}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/15-EJS1007}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/15-EJS1007}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="6678714" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Genetically Informed, Group fMRI Connectivity Modeling Approach: Application to Schizophrenia</div>
          <!-- Author -->
          <div class="author">
          

          Aiping Liu, <em>Xiaohui Chen</em>, <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>, Qi Xu, Silke Appel-Cresswell, and <a href="https://neurology.med.ubc.ca/faculty-listing/academic/martin-j-mckeown/" target="_blank" rel="noopener noreferrer">Martin J. McKeown</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Biomedical Engineering</em> Mar 2014
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>While neuroimaging data can provide valuable phenotypic information to inform genetic studies, the opposite is also true: known genotypes can be used to inform brain connectivity patterns from fMRI data. Here, we propose a framework for genetically informed group brain connectivity modeling. Subjects are first stratified according to their genotypes, and then a group regularized regression model is employed for brain connectivity modeling utilizing the time courses from a priori specified regions of interest (ROIs). With such an approach, each ROI time course is in turn predicted from all other ROI time courses at zero lag using a group regression framework which also incorporates a penalty based on genotypic similarity. Simulations supported such an approach when, as previously studies have indicated to be the case, genetic influences impart connectivity differences across subjects. The proposed method was applied to resting state fMRI data from Schizophrenia and normal control subjects. Genotypes were based on D-amino acid oxidase activator (DAOA) single-nucleotide polymorphisms (SNPs) information. With DAOA SNPs information integrated, the proposed approach was able to more accurately model the diversity in connectivity patterns. Specifically, connectivity with the left putamen, right posterior cingulate, and left middle frontal gyri were found to be jointly modulated by DAOA genotypes and the presence of Schizophrenia. We conclude that the proposed framework represents a multimodal analysis approach for incorporating genotypic variability into brain connectivity analysis directly.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">6678714</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Aiping and Chen, Xiaohui and Wang, Z. Jane and Xu, Qi and Appel-Cresswell, Silke and McKeown, Martin J.}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:51:47 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 15:51:47 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TBME.2013.2294151}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1558-2531}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Biomedical Engineering}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{946-956}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Genetically Informed, Group fMRI Connectivity Modeling Approach: Application to Schizophrenia}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{61}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TBME.2013.2294151}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="CHEN201483" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A note on moment inequality for quadratic forms</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Statistics &amp; Probability Letters</em> Mar 2014
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1404.1406" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Moment inequality for quadratic forms of random vectors is of particular interest in covariance matrix testing and estimation problems. In this paper, we prove a Rosenthal-type inequality, which exhibits new features and certain improvement beyond the unstructured Rosenthal inequality of quadratic forms when dimension of the vectors increases without bound. Applications to test the block diagonal structures and detect the sparsity in the high-dimensional covariance matrix are presented.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CHEN201483</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:50:26 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:51:56 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.spl.2014.05.004}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0167-7152}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Statistics &amp; Probability Letters}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Quadratic forms, Rosenthal's inequality, High-dimensional covariance matrix}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{83-88}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A note on moment inequality for quadratic forms}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0167715214001801}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{92}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0167715214001801}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.spl.2014.05.004}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2013</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1214/13-AOS1182" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Covariance and precision matrix estimation for high-dimensional time series</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, Mengyu Xu, and <a href="https://www.stat.uchicago.edu/~wbwu/" target="_blank" rel="noopener noreferrer">Wei Biao Wu</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>The Annals of Statistics</em> Mar 2013
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://arxiv.org/abs/1401.0993" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="/assets/pdf/suppl-oct-10-2013-accepted.pdf" class="btn btn-sm z-depth-0" role="button">Supp</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We consider estimation of covariance matrices and their inverses (a.k.a. precision matrices) for high-dimensional stationary and locally stationary time series. In the latter case the covariance matrices evolve smoothly in time, thus forming a covariance matrix function. Using the functional dependence measure of Wu [Proc. Natl. Acad. Sci. USA 102 (2005) 14150–14154 (electronic)], we obtain the rate of convergence for the thresholded estimate and illustrate how the dependence affects the rate of convergence. Asymptotic properties are also obtained for the precision matrix estimate which is based on the graphical Lasso principle. Our theory substantially generalizes earlier ones by allowing dependence, by allowing nonstationarity and by relaxing the associated moment conditions.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1214/13-AOS1182</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Xu, Mengyu and Wu, Wei Biao}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:57:31 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-30 08:53:51 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1214/13-AOS1182}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Annals of Statistics}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{consistency, Covariance matrix, Dependence, functional dependence measure, high-dimensional inference, Lasso, Nagaev inequality, nonstationary time series, precision matrix, Sparsity, spatial--temporal processes, thresholding}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2994 -- 3021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Mathematical Statistics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Covariance and precision matrix estimation for high-dimensional time series}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/13-AOS1182}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{41}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2013}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1214/13-AOS1182}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2012</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="6288303" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Large covariance matrix estimation: Bridging shrinkage and tapering approaches</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>, and <a href="https://neurology.med.ubc.ca/faculty-listing/academic/martin-j-mckeown/" target="_blank" rel="noopener noreferrer">Martin J. McKeown</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> Mar 2012
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we propose a shrinkage-to-tapering oracle (STO) estimator for estimation of large covariance matrix when the number of samples is substantially fewer than the number of variables, by combining the strength from both Steinian-type shrinkage and tapering estimators. Our contributions include: (i) Deriving the Frobenius risk and a lower bound for the spectral risk of an MMSE shrinkage estimator; (ii) Deriving a closed-form expression for the optimal coefficient of the proposed STO estimator. Simulations on auto-regression (e.g. a sparse case) and fraction Brownian motion (e.g. a non-sparse case) covariance structures are used to demonstrate the superiority of the proposed estimator.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">6288303</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Wang, Z. Jane and McKeown, Martin J.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 18:31:31 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 18:31:31 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP.2012.6288303}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2379-190X}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2013-2016}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Large covariance matrix estimation: Bridging shrinkage and tapering approaches}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICASSP.2012.6288303}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="6252067" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Shrinkage-to-Tapering Estimation of Large Covariance Matrices</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>, and <a href="https://neurology.med.ubc.ca/faculty-listing/academic/martin-j-mckeown/" target="_blank" rel="noopener noreferrer">Martin J. McKeown</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Signal Processing</em> Nov 2012
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we introduce a shrinkage-to-tapering approach for estimating large covariance matrices when the number of samples is substantially fewer than the number of variables (i.e., n,p→∞ and p/n→∞). The proposed estimator improves upon both shrinkage and tapering estimators by shrinking the sample covariance matrix to its tapered version. We first show that, under both normalized Frobenius and spectral risks, the minimum mean-squared error (MMSE) shrinkage-to-identity estimator is inconsistent and outperformed by a minimax tapering estimator for a class of high-dimensional and diagonally dominant covariance matrices. Motivated by this observation, we propose a shrinkage-to-tapering oracle (STO) estimator for efficient estimation of general, large covariance matrices. A closed-form formula of the optimal coefficient ρ of the proposed STO estimator is derived under the minimum Frobenius risk. Since the true covariance matrix is to be estimated, we further propose a STO approximating (STOA) algorithm with a data-driven bandwidth selection procedure to iteratively estimate the coefficient ρ and the covariance matrix. We study the finite sample performances of different estimators and our simulation results clearly show the improved performances of the proposed STO estimators. Finally, the proposed STOA method is applied to a real breast cancer gene expression data set.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">6252067</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Wang, Z. Jane and McKeown, Martin J.}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:59:26 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 15:59:26 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TSP.2012.2210546}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1941-0476}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Signal Processing}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5640-5656}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Shrinkage-to-Tapering Estimation of Large Covariance Matrices}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{60}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TSP.2012.2210546}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="6159094" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Efficient Minimax Estimation of a Class of High-Dimensional Sparse Precision Matrices</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, <a href="https://personal.math.ubc.ca/~yhkim/" target="_blank" rel="noopener noreferrer">Young-Heon Kim</a>, and <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Signal Processing</em> Jun 2012
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Estimation of the covariance matrix and its inverse, the precision matrix, in high-dimensional situations is of great interest in many applications. In this paper, we focus on the estimation of a class of sparse precision matrices which are assumed to be approximately inversely closed for the case that the dimensionality p can be much larger than the sample size n, which is fundamentally different from the classical case that p &lt;; n. Different in nature from state-of-the-art methods that are based on penalized likelihood maximization or constrained error minimization, based on the truncated Neumann series representation, we propose a computationally efficient precision matrix estimator that has a computational complexity of O (p3). We prove that the proposed estimator is consistent in probability and in L2 under the spectral norm. Moreover, its convergence is shown to be rate-optimal in the sense of minimax risk. We further prove that the proposed estimator is model selection consistent by establishing a convergence result under the entry-wise ∞-norm. Simulations demonstrate the encouraging finite sample size performance and computational advantage of the proposed estimator. The proposed estimator is also applied to a real breast cancer data and shown to outperform existing precision matrix estimators.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">6159094</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Kim, Young-Heon and Wang, Z. Jane}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 15:58:51 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 15:58:51 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TSP.2012.2189109}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1941-0476}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Signal Processing}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2899-2912}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Efficient Minimax Estimation of a Class of High-Dimensional Sparse Precision Matrices}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{60}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TSP.2012.2189109}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="pmlr-v22-chen12b" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Two-Graph Guided Multi-task Lasso Approach for eQTL Mapping</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, Xinghua Shi, Xing Xu, Zhiyong Wang, Ryan Mills, Charles Lee, and Jinbo Xu</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS)</em> 21–23 apr 2012
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="https://proceedings.mlr.press/v22/chen12b.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://github.com/xiaohuichen88/MMT" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning a small number of genetic variants associated with multiple complex genetic traits is of practical importance and remains challenging due to the high dimensional nature of data. In this paper, we proposed a two-graph guided multi-task Lasso to address this issue with an emphasis on estimating subnetwork-to-subnetwork associations in expression quantitative trait loci (eQTL) mapping. The proposed model can learn such subnetwork-to-subnetwork associations and therefore can be seen as a generalization of several state-of-the-art multi-task feature selection methods. Additionally, this model has a nice property of allowing flexible structured sparsity on both feature and label domains. Simulation study shows the improved performance of our model and a human eQTL data set is analyzed to further demonstrate the applications of the model.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v22-chen12b</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{La Palma, Canary Islands}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Shi, Xinghua and Xu, Xing and Wang, Zhiyong and Mills, Ryan and Lee, Charles and Xu, Jinbo}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:04:40 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-12-26 14:08:18 -0600}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Lawrence, Neil D. and Girolami, Mark}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{21--23 Apr}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{208--217}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Two-Graph Guided Multi-task Lasso Approach for eQTL Mapping}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{22}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2012}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2011</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="CHEN20111920" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Bayesian Lasso via reversible-jump MCMC</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>, and <a href="https://neurology.med.ubc.ca/faculty-listing/academic/martin-j-mckeown/" target="_blank" rel="noopener noreferrer">Martin J. McKeown</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Signal Processing</em> 21–23 apr 2011
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Variable selection is a topic of great importance in high-dimensional statistical modeling and has a wide range of real-world applications. Many variable selection techniques have been proposed in the context of linear regression, and the Lasso model is probably one of the most popular penalized regression techniques. In this paper, we propose a new, fully hierarchical, Bayesian version of the Lasso model by employing flexible sparsity promoting priors. To obtain the Bayesian Lasso estimate, a reversible-jump MCMC algorithm is developed for joint posterior inference over both discrete and continuous parameter spaces. Simulations demonstrate that the proposed RJ-MCMC-based Bayesian Lasso yields smaller estimation errors and more accurate sparsity pattern detection when compared with state-of-the-art optimization-based Lasso-type methods, a standard Gibbs sampler-based Bayesian Lasso and the Binomial–Gaussian prior model. To demonstrate the applicability and estimation stability of the proposed Bayesian Lasso, we examine a benchmark diabetes data set and real functional Magnetic Resonance Imaging data. As an extension of the proposed RJ-MCMC framework, we also develop an MCMC-based algorithm for the Binomial–Gaussian prior model and illustrate its improved performance over the non-Bayesian estimate via simulations.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">CHEN20111920</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Wang, Z. Jane and McKeown, Martin J.}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 16:00:24 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-30 23:55:22 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.sigpro.2011.02.014}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0165-1684}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Signal Processing}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Sparse signal recovery, Variable selection, Dimensionality reduction, Fully Bayesian modeling, Reversible-jump Markov chain Monte Carlo (RJ-MCMC), Lasso}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1920-1932}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Bayesian Lasso via reversible-jump MCMC}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0165168411000703}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{91}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2011}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0165168411000703}</span><span class="p">,</span>
  <span class="na">bdsk-url-2</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.sigpro.2011.02.014}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2010</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="5495338" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Asymptotic analysis of the Huberized LASSO estimator</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>, and <a href="https://neurology.med.ubc.ca/faculty-listing/academic/martin-j-mckeown/" target="_blank" rel="noopener noreferrer">Martin J. McKeown</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2010 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> Mar 2010
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The Huberized LASSO model, a robust version of the popular LASSO, yields robust model selection in sparse linear regression. Though its superior performance was empirically demonstrated for large variance noise, currently no theoretical asymptotic analysis has been derived for the Huberized LASSO estimator. Here we prove that the Huberized LASSO estimator is consistent and asymptotically normal distributed under a proper shrinkage rate. Our derivation shows that, unlike the LASSO estimator, its asymptotic variance is stabilized in the presence of noise with large variance. We also propose the adaptive Huberized LASSO estimator by allowing unequal penalty weights for the regression coefficients, and prove its model selection consistency. Simulations confirm our theoretical results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">5495338</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Wang, Z. Jane and McKeown, Martin J.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2010 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 18:34:44 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-15 08:25:27 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICASSP.2010.5495338}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2379-190X}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1898-1901}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Asymptotic analysis of the Huberized LASSO estimator}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICASSP.2010.5495338}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="5652779" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">FMRI group studies of brain connectivity via a group robust Lasso</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>, and <a href="https://neurology.med.ubc.ca/faculty-listing/academic/martin-j-mckeown/" target="_blank" rel="noopener noreferrer">Martin J. McKeown</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2010 IEEE International Conference on Image Processing (ICIP)</em> Sep 2010
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Inferring effective brain connectivity from neuroimaging data such as functional Magnetic Resonance Imaging (fMRI) has been attracting increasing interest due to its critical role in understanding brain functioning. Incorporating sparsity into connectivity modeling to make models more biologically realistic and performing group analysis to deal with inter-subject variability are still challenges associated with fMRI brain connectivity modeling. To address the above two crucial challenges, the attractive computational and theoretical properties of the least absolute shrinkage and selection operator (LASSO) in sparse linear regression provide a suitable starting point. We propose a group robust LASSO (grpRLASSO) model by combining advantages of the popular group-LASSO and our recently developed robust-LASSO. Here group analysis is formulated as a grouped variable selection procedure. Superior performance of the proposed grpRLASSO in terms of group selection and robustness is demonstrated by simulations with large noise variance. The grpRLASSO is also applied to a real fMRI data set for brain connectivity study in Parkinson’s disease, resulting in biologically plausible networks.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">5652779</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Wang, Z. Jane and McKeown, Martin J.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2010 IEEE International Conference on Image Processing (ICIP)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 18:34:02 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-15 08:25:37 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICIP.2010.5652779}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2381-8549}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{589-592}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FMRI group studies of brain connectivity via a group robust Lasso}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICIP.2010.5652779}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="5571842" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Asymptotic Analysis of Robust LASSOs in the Presence of Noise With Large Variance</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, <a href="https://people.ece.ubc.ca/zjanew/" target="_blank" rel="noopener noreferrer">Z. Jane Wang</a>, and <a href="https://neurology.med.ubc.ca/faculty-listing/academic/martin-j-mckeown/" target="_blank" rel="noopener noreferrer">Martin J. McKeown</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Information Theory</em> Oct 2010
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In the context of linear regression, the least absolute shrinkage and selection operator (LASSO) is probably the most popular supervised-learning technique proposed to recover sparse signals from high-dimensional measurements. Prior literature has mainly concerned itself with independent, identically distributed noise with moderate variance. In many real applications, however, the measurement errors may have heavy-tailed distributions or suffer from severe outliers, making the LASSO poorly estimate the coefficients due to its sensitivity to large error variance. To address this concern, a robust version of the LASSO is proposed, and the limiting distribution of its estimator is derived. Model selection consistency is established for the proposed robust LASSO under an adaptation procedure of the penalty weight. A parallel asymptotic analysis is derived for the Huberized LASSO, a previously proposed robust LASSO, and it is shown that the Huberized LASSO estimator preserves similar asymptotics even with a Cauchy error distribution. We show that asymptotic variances of the two robust LASSO estimators are stabilized in the presence of large variance noise, compared with the unbounded asymptotic variance of the ordinary LASSO estimator. The asymptotic analysis from the nonstochastic design is extended to the case of random design. Simulations further confirm our theoretical results.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">5571842</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Wang, Z. Jane and McKeown, Martin J.}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 18:32:56 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 18:32:56 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TIT.2010.2059770}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1557-9654}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Information Theory}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5131-5149}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Asymptotic Analysis of Robust LASSOs in the Presence of Noise With Large Variance}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{56}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2010}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/TIT.2010.2059770}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2009</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Conference</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="5162334" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">An MM-Based Optimization Algorithm for Sparse Linear Modeling on Microarray Data Analysis</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, and <a href="https://www.sib.swiss/raphael-gottardo-group/" target="_blank" rel="noopener noreferrer">Raphael Gottardo</a>
</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 2009 3rd International Conference on Bioinformatics and Biomedical Engineering (ICBBE)</em> Jun 2009
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Sparsity is crucial for high-dimensional statistical modeling. On one hand, dimensionality reduction can reduce the variability of estimation and thus provide reliable predictive power. On the other hand, the selected sub-model can discover and emphasize the underlying dependencies, which is useful for objective interpretation. Many variable selection methods have been proposed in literatures. For a prominent example, Least Absolute Shrinkage and Selection Operator (lasso) in linear regression context has been extensively explored. This paper discusses a class of scaled mixture of Gaussian models from both a penalized likelihood and a Bayesian regression point of view. We propose an Majorize-Minimize (MM) algorithm to find the Maximum A Posteriori (MAP) estimator, where the EM algorithm can be stuck at local optimum for some members in this class. Simulation studies show the outperformance of proposed algorithm in nonstochastic design variable selection scenario. The proposed algorithm is applied to a real large-scale E.coli data set with known bona fide interactions for constructing sparse gene regulatory networks. We show that our regression networks with a properly chosen prior can perform comparably to state-of-the-art regulatory network construction algorithms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">5162334</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Gottardo, Raphael}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2009 3rd International Conference on Bioinformatics and Biomedical Engineering (ICBBE)}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 18:36:41 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-09-15 08:26:23 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICBBE.2009.5162334}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2151-7622}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-4}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An MM-Based Optimization Algorithm for Sparse Linear Modeling on Microarray Data Analysis}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2009}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICBBE.2009.5162334}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2006</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:var(--global-badge_background-color)"><a href="">Journal</a></abbr></div>

  
        <!-- Entry bib key -->
        <div id="10.1093/bioinformatics/btl491" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">BNArray: an R package for constructing gene regulatory networks from microarray data by using Bayesian network</div>
          <!-- Author -->
          <div class="author">
          

          <em>Xiaohui Chen</em>, Ming Chen, and Kaida Ning</div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Bioinformatics</em> Sep 2006
          </div>
<!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Summary:BNArray is a systemized tool developed in R. It facilitates the construction of gene regulatory networks from DNA microarray data by using Bayesian network. Significant sub-modules of regulatory networks with high confidence are reconstructed by using our extended sub-network mining algorithm of directed graphs. BNArray can handle microarray datasets with missing data. To evaluate the statistical features of generated Bayesian networks, re-sampling procedures are utilized to yield collections of candidate 1st-order network sets for mining dense coherent sub-networks.Availability: The R package and the supplementary documentation are available at .Contact:mchen@zju.edu.cn</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1093/bioinformatics/btl491</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Xiaohui and Chen, Ming and Ning, Kaida}</span><span class="p">,</span>
  <span class="na">date-added</span> <span class="p">=</span> <span class="s">{2022-08-29 09:22:54 -0500}</span><span class="p">,</span>
  <span class="na">date-modified</span> <span class="p">=</span> <span class="s">{2022-08-29 09:25:43 -0500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1093/bioinformatics/btl491}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1367-4803}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Bioinformatics}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{23}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2952-2954}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{BNArray: an R package for constructing gene regulatory networks from microarray data by using Bayesian network}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/bioinformatics/btl491}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{22}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2006}</span><span class="p">,</span>
  <span class="na">bdsk-url-1</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/bioinformatics/btl491}</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2026 Xiaohui  Chen. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
